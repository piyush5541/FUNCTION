{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRwcYZVkf5vs"
      },
      "outputs": [],
      "source": [
        "# What is a parameter?\n",
        "\n",
        "- A parameter is a configuration variable that is internal to the model and whose value can be estimated from data. In machine learning , model parameters are learned during training and used to make prediction.\n",
        "\n",
        "# What is correlation?\n",
        "\n",
        "- Correlation is a statistical measure that describes the relationship between two variables.It shows how changes in one variable are associated with changes in another.\n",
        "\n",
        "# What does negative correlation mean ?\n",
        "\n",
        "- Negative correlation means that as one variable increases . For example , the more time you spend exercising , the less you might weigh.\n",
        "\n",
        "# Define Machine Learning . What are the main components in Machine Learning?\n",
        "\n",
        "- Machine Learning is a subset of AI that focuses on developing algorithms and models that enable computers to learn from data without being explicitly programmed. Main component- Data, Model(Algorithm), Evaluation metrics , loss function , optimizer.\n",
        "\n",
        "# How does loss value help in determining whether the model is good or not ?\n",
        "\n",
        "- The loss value quantifies the error between predicted and actual outcomes . A lower loss indicates better performance, while a higher loss suggests poor predictions.\n",
        "\n",
        "# What is continuous and categorical variables?\n",
        "\n",
        "- Continuous variables: Numeric values that can take any value within a range (e.g, height, salary).\n",
        "- Categorical variables: Variables with fixed possible values or categories (e.g., gender, color).\n",
        "\n",
        "# How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "- common techniques include.\n",
        ". Label Encoding\n",
        ". One-Hot Encoding\n",
        ". Ordinal Encoding\n",
        ". Binary Encoding\n",
        "\n",
        "# What do you mean by training and testing a dataset?\n",
        "\n",
        ". Training set: Data used to train the model.\n",
        ". Testing set: Data used to evaluate the model's performance.\n",
        "\n",
        "# What is sklearn.preprocessing/\n",
        "\n",
        "- Its a module in scikit-learn that provides tools for feature preprocessing like:\n",
        ". Scaling\n",
        ". Normalization\n",
        ". Encoding categorical variables\n",
        "\n",
        "# What is a test set?\n",
        "\n",
        "- A test set is a seperate portion of the dataset used to evaluate the performance of a machine learning model. It is used to assess how well the model generalizes to unseen data.\n",
        "\n",
        "# How do we split data for model fitting (training and testing ) in Python/\n",
        "\n",
        "- Using train _test_split() function from sklearn.model_selection:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# How do you approach a Machine Learning problem?\n",
        "\n",
        "- steps.\n",
        ". Define the problem\n",
        ". collect data\n",
        ". Explore and preprocess data\n",
        ". Choose model(s)\n",
        ". Train model\n",
        ". Evaluate and fine-tune\n",
        ". Deploy and monitor\n",
        "\n",
        "# Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "- EDA(Exploratory Data Analysis) helps understand data patterns, detect anomalies, handle missing values, and choose suitable preprocessing steps.\n",
        "\n",
        "# How can you find correlation between variables in Python?\n",
        "\n",
        "- Using .corr() from pandas:\n",
        "- df.corr()\n",
        "\n",
        "# What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "- Causation: implies one variable causes a change in another.\n",
        "- correlation: just shows an association.\n",
        "\n",
        "Example; Ice Cream sales and drowning deaths are correlated (both increase in summer ) but ice cream doesnt cause drowning-this is not causation.\n",
        "\n",
        "# What is an optimizer? What are different types of optimizer? Expalin each with an example.\n",
        "\n",
        "- Optimizer updates model parameters to minimize loss.\n",
        ". SGD(Stochastic Gradient Descent)\n",
        ". Adam\n",
        ". RMSProp\n",
        "\n",
        "Example: optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# What is sklearn.linear_model?\n",
        "\n",
        "- A module in scikit-learn containing linear model like:\n",
        ". Linear Regression\n",
        ". Logistic Regression\n",
        ". Ridge Regression\n",
        ". Lasso Regression\n",
        ". Elastic Net Regression\n",
        "\n",
        "# What does model.fit() do? What argument must be given?\n",
        "\n",
        "- model.fit() trains the model using training data.\n",
        "\n",
        "Arguments:\n",
        ". x - feature data\n",
        ". y - target values\n",
        "\n",
        "# What does model.predict() do? What arguments must be given?\n",
        "\n",
        "- model.predict() makes predictions using the trained model.\n",
        "Argument:\n",
        ". x - feature data\n",
        "\n",
        "# What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling transforms features to a common scale. It helps algorithms converge faster and improve accuracy for models sensitive to feature magnitudes.\n",
        "\n",
        "# How do we perform scaling in Python?\n",
        "\n",
        "- Using Standardscaler or MinMaxScaler from sklearn.preprocessing:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# What is sklearn.preprocessing?\n",
        "\n",
        "- A module in scikit-learn containing preprocessing tools like:\n",
        ". Scaling\n",
        ". Normalization\n",
        ". Encoding categorical variables\n",
        "\n",
        "# How do we split data for model fitting in python?\n",
        "\n",
        "- Using train_test_split() from sklearn.model_selection:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Explain data encoding?\n",
        "\n",
        "- Data encoding transforms categorical data into numerical format so ML models can use it.\n",
        "Techniques:\n",
        ". Label Encoding\n",
        ". One-Hot Encoding\n",
        ". Ordinal Encoding\n",
        ". Binary Encoding"
      ]
    }
  ]
}