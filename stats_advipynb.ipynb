{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1. What is a random variable in probability theory?\n",
        "\n",
        ". In probability theory, a random variable is a function that assigns a real number to each possible outcome in the sample space of an experiment. For instance, if you flip two coins, the number of heads (0, 1, or 2) can be a random variable.\n",
        "\n",
        "#2. What are the types of random variables?\n",
        "\n",
        ". Discrete Random Variable\n",
        ". Continous Random Variable\n",
        "\n",
        "#3.What is the difference between discrete and continuous distributions?\n",
        "\n",
        ". Discrete distributions deal with outcomes that can be counted, like whole numbers (e.g., number of heads in coin flips), where each specific value has a measurable probability. Continuous distributions, on the other hand, apply to outcomes that can take any value within a range (e.g., height or temperature), where the probability of any single exact value is technically zero, and instead, probabilities are given for ranges of values (represented by the area under a curve).\n",
        "\n",
        "#4. What are probability distribution functions (PDF)?\n",
        "\n",
        ". A probability distribution function is a rule tells us the chance of every possible outcome in a random situation. For discrete outcomes, it's called a Probability Mass Function (PMF), while for continuous outcomes, it's a Probability Density Function (PDF).\n",
        "\n",
        "#5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "\n",
        ". A Probability Distribution Function (PDF) shows the likelihood of a random variable taking on a specific value (for discrete data, it's a Probability Mass Function, PMF) or its probability density around a value (for continuous data).\n",
        "A Cumulative Distribution Function (CDF), on the other hand, gives the accumulated probability that a random variable will be less than or equal to a certain value. It basically sums up all the probabilities from the lowest possible value up to that point.\n",
        "\n",
        "#6. What is a discrete uniform distribution?\n",
        "\n",
        ". A discrete uniform distribution means that in a set of distinct, countable outcomes, each outcome has exactly the same probability of happening.\n",
        "\n",
        "\n",
        "#7. What are the key properties of a Bernoulli distribution?\n",
        "\n",
        ". A Bernoulli distribution models a single event with only two possible outcomes: \"success\" (usually coded as 1) or \"failure\" (usually coded as 0). It's defined by a single parameter, 'p', which is the probability of success. The probability of failure is then 1-p.\n",
        "\n",
        "#8. What is the binomial distribution, and how is it used in probability?\n",
        "\n",
        ".  The binomial distribution calculates the probability of getting a specific number of \"successes\" in a fixed number of independent trials, where each trial has only two possible outcomes (like yes/no, heads/tails). It's used when you want to know the chances of an event happening a certain number of times in a series of identical experiments, such as predicting how many heads you'll get in 10 coin flips\n",
        "\n",
        "#9. What is the Poisson distribution and where is it applied?\n",
        "\n",
        ".  The Poisson distribution is a discrete probability distribution that models the number of times an event occurs within a fixed interval of time or space.It's used for counting rare events, such as the number of customer calls a call center receives in an hour, the number of defects on a manufactured product per square meter, etc.\n",
        "\n",
        "#10. What is a continuous uniform distribution?\n",
        "\n",
        ". A continuous uniform distribution describes a situation where all values within a specific range are equally likely to occur. nlike discrete uniform, it applies to continuous data, meaning any value within the defined interval has the same \"density\" of probability.\n",
        "\n",
        "#11. What are the characteristics of a normal distribution?\n",
        "\n",
        ". A normal distribution, often called the \"bell curve,\" is symmetrical around its center, where the mean, median, and mode are all equal.\n",
        ". Most of the data clusters around this center, with fewer data points further away, creating a characteristic bell shape.\n",
        ". Its spread is defined by the standard deviation, and approximately 68%, 95%, and 99.7% of the data fall within 1, 2, and 3 standard deviations of the mean, respectively.\n",
        "\n",
        "#12. What is the standard normal distribution, and why is it important?\n",
        "\n",
        ". The standard normal distribution is a special normal distribution with a mean of 0 and a standard deviation of 1. It's important because any normal distribution can be converted into it using a simple formula (z-score).This allows us to easily compare data from different normal distributions and use standardized tables to calculate probabilities, which simplifies many statistical analyses and hypothesis tests.\n",
        "\n",
        "#13. What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "\n",
        ". The Central Limit Theorem (CLT) states that if you take many large random samples from any population, the distribution of the sample means will tend to be normally distributed, regardless of the original population's shape.\n",
        "\n",
        "#14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "\n",
        ". The Central Limit Theorem (CLT) explains why the distribution of sample means tends to be normal, even if the original data isn't. As sample size increases, the shape of the sampling distribution of the mean becomes more like a normal distribution. This allows us to use normal distribution tools for inference.\n",
        "\n",
        "#15. What is the application of Z statistics in hypothesis testing?\n",
        "\n",
        ". It measures how many standard deviations a sample mean is away from the hypothesized population mean. It's used when the population's standard deviation is known and the sample size is large. By comparing the calculated Z-statistic to critical values from the standard normal distribution, we determine if the observed sample mean is significantly different enough to reject the null hypothesis.\n",
        "\n",
        "#16. How do you calculate a Z-score, and what does it represent?\n",
        "\n",
        ". It is calculated by Z = x - mean / standard deviation, where x is data point. A positive Z-score means the data point is above the average, while a negative Z-score means it's below. It helps you understand how \"unusual\" a particular data point is relative to the rest of the data.\n",
        "\n",
        "#17. What are point estimates and interval estimates in statistics?\n",
        "\n",
        ". Point Estimates is a single value for to estimate an unknown populatino parameter using sample. Ex - Avg salary is used to estimate the avg salary of population.\n",
        "\n",
        ". Interval Estimate provides a range of values that is used to estimate the unknown population parameter. Ex - Marks of student between 200 - 400.\n",
        "\n",
        "#18. What is the significance of confidence intervals in statistical analysis?\n",
        "\n",
        ".  Confidence intervals provide a range of values within which we expect the true population parameter to fall, based on sample data. They give us an idea of the precision and reliability of our estimates. A wider interval suggests more uncertainty, while a narrower one implies greater confidence. For example, a 95% confidence interval means we expect the true value to fall within that range 95 times out of 100.\n",
        "\n",
        "#19. What is the relationship between a Z-score and a confidence interval?\n",
        "\n",
        ". A Z-score represents how many standard deviations a value is from the mean in a standard normal distribution. In confidence intervals, Z-scores are used to determine the margin of error. For example, a 95% confidence interval uses a Z-score of about 1.96, meaning the interval includes values within 1.96 standard deviations of the mean. Higher confidence levels correspond to larger Z-scores.\n",
        "\n",
        "#20. How are Z-scores used to compare different distributions?\n",
        "\n",
        ". Z-scores standardize values from different distributions by converting them into a common scale based on their mean and standard deviation. This allows you to compare values from different datasets, even if the original units or spreads are different. A higher Z-score means a value is further above the mean, while a negative Z-score means it's below. This makes it easier to see which value is more extreme relative to its own distribution.\n",
        "\n",
        "#21. What are the assumptions for applying the Central Limit Theorem?\n",
        "\n",
        ". Random Sampling: The samples must be drawn randomly from the population.\n",
        ".Independence: The observations within the sample must be independent of each other.\n",
        ".Finite Variance: The population from which the samples are drawn must have a finite mean and variance.\n",
        "\n",
        "#22. What is the concept of expected value in a probability distribution?\n",
        "\n",
        ". The expected value is the average outcome you would expect if you repeated a random experiment many times. Itâ€™s calculated by multiplying each possible value by its probability and then adding them up. It gives a measure of the \"center\" of the probability distribution.\n",
        "\n",
        "#23. How does a probability distribution relate to the expected outcome of a random variable?\n",
        "\n",
        ".  A probability distribution lists all possible outcomes of a random variable and their corresponding probabilities. The expected outcome is essentially the long-term average of these outcomes, calculated by weighting each possible value by its probability. So, the probability distribution provides the necessary information to calculate this expected outcome.\n",
        ""
      ],
      "metadata": {
        "id": "02UhDQ78uuj4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}